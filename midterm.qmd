---
title: "Midterm Project"
author: "Thomas Schittina"
toc: true
highlight-style: pygments
format: 
  html: 
    code-fold: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true	
  pdf: 
    geometry: 
      - top=30mm
      - left=20mm
---

## Data Cleaning

### (a) Import Data

After reading in the dataset, we rename the columns in accordance with standard 
naming conventions. Next, we convert the datatype of a few columns we know will 
be important later. The first two columns, `created_date` and `closed_date`, 
are converted to datetime objects, and `incident_zip` is recast to contain 
strings. For the sake of the conversion, any `NaN` in `incident_zip` is 
replaced by the value 0, which we will handle later.

```{python}
import pandas as pd
import numpy as np

# read coordinates in as 32-bit float
df = pd.read_csv('data/nycflood2024.csv',
                 dtype={'Latitude': np.float32, 'Longitude': np.float32,})

# ensure columns comply with naming conventions
df.columns = df.columns.str.lower().str.replace(' ', '_')

# convert to datetime objects
df['created_date'] = pd.to_datetime(df['created_date'],
                                    format='%m/%d/%Y %I:%M:%S %p')
df['closed_date'] = pd.to_datetime(df['closed_date'],
                                   format='%m/%d/%Y %I:%M:%S %p')

# convert zip codes to strings, convert NaN to zero (fill later)
df['incident_zip'] = df['incident_zip'].fillna(0).astype(int).astype(str)
```

### (b) Summarize missing information

The method `df.info()` is used to summarize missing information. It reveals 
that 11 columns are completely null. By referencing the website's explanation 
of these missing variables, we see that none of them pertain to flood data. 
Therefore, it is safe to drop these columns; they will not provide any insight 
or predictive power to our model.

```{python}
# drop entirely null columns
df = df.dropna(axis=1, how='all')
```

This leaves us with 30 columns, most of which are missing little to no 
information.

### (c) Redundant information and feather format

Any column consisting of one unique value will not provide any insight we can 
leverage in our model. Their lack of variation makes them redundant.

```{python}
# identify and drop columns with no variation
to_drop = list(df.columns[df.nunique() == 1])
df = df.drop(columns=to_drop)
```

Now, we can reference the website's data dictionary to identify other columns 
that may be unnecessary. Our search indicates `street_name` may be redundant 
given we already have `incident_address`. Further inspection reveals this to be 
the case. We also find that much of the geographic/location data is repeated in 
various columns. We will drop all of these redundant variables.

```{python}
# drop other redundant columns
to_drop = ['street_name', 'x_coordinate_(state_plane)',
           'y_coordinate_(state_plane)', 'bbl', 'park_borough', 'location']
df = df.drop(columns=to_drop)
```

### (d)